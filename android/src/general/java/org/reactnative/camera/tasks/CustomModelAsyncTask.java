package org.reactnative.camera.tasks;

import android.content.res.AssetManager;
import android.graphics.ImageFormat;
import android.graphics.Rect;
import android.graphics.YuvImage;
import android.util.Log;
import android.graphics.BitmapFactory;
import android.graphics.Bitmap;
import android.graphics.Color;

import com.facebook.react.bridge.Arguments;
import com.facebook.react.bridge.WritableArray;
import com.facebook.react.uimanager.ThemedReactContext;
import com.facebook.react.bridge.ReactApplicationContext;

import com.google.android.gms.tasks.OnFailureListener;
import com.google.android.gms.tasks.OnSuccessListener;

import java.io.ByteArrayOutputStream;
import java.io.FileNotFoundException;

import com.google.firebase.ml.common.FirebaseMLException;
import com.google.firebase.ml.custom.FirebaseCustomLocalModel;
import com.google.firebase.ml.custom.FirebaseModelDataType;
import com.google.firebase.ml.custom.FirebaseModelInputOutputOptions;
import com.google.firebase.ml.custom.FirebaseModelInputs;
import com.google.firebase.ml.custom.FirebaseModelInterpreter;
import com.google.firebase.ml.custom.FirebaseModelInterpreterOptions;
import com.google.firebase.ml.custom.FirebaseModelOutputs;

import org.reactnative.camera.utils.ImageDimensions;

public class CustomModelAsyncTask extends android.os.AsyncTask<Void, Void, Void> {

    private CustomModelAsyncTaskDelegate mDelegate;
    private ThemedReactContext mThemedReactContext;
    private byte[] mImageData;
    private int mWidth;
    private int mHeight;
    private int mRotation;
    private double mScaleX;
    private double mScaleY;
    private ImageDimensions mImageDimensions;
    private int mPaddingLeft;
    private int mPaddingTop;
    private String TAG = "RNCamera";

    //Custom Model variables

    private static final int DIM_BATCH_SIZE = 1;
    private static final int DIM_PIXEL_SIZE = 3;
    private static final int DIM_IMG_SIZE_X = 400; //368;
    private static final int DIM_IMG_SIZE_Y = 400;//368;

    private static ReactApplicationContext reactContext;

    private FirebaseModelInterpreter mInterpreter;

    private FirebaseModelInputOutputOptions mDataOptions;

    public CustomModelAsyncTask(
            CustomModelAsyncTaskDelegate delegate,
            ThemedReactContext themedReactContext,
            byte[] imageData,
            int width,
            int height,
            int rotation,
            float density,
            int facing,
            int viewWidth,
            int viewHeight,
            int viewPaddingLeft,
            int viewPaddingTop
    ) {
        mThemedReactContext = themedReactContext;
        mDelegate = delegate;
        mImageData = imageData;
        mWidth = width;
        mHeight = height;
        mRotation = rotation;
        mImageDimensions = new ImageDimensions(width, height, rotation, facing);
        mScaleX = (double) (viewWidth) / (mImageDimensions.getWidth() * density);
        mScaleY = (double) (viewHeight) / (mImageDimensions.getHeight() * density);
        mPaddingLeft = viewPaddingLeft;
        mPaddingTop = viewPaddingTop;
    }

    @Override
    protected Void doInBackground(Void... ignored) {

        System.out.println("rentr√© dans background");
        if (isCancelled() || mDelegate == null) {
            return null;
        }

        //mLabelList = loadLabelList(mThemedReactContext);

        try {

            mDataOptions = new FirebaseModelInputOutputOptions.Builder()
                    .setInputFormat(0, FirebaseModelDataType.FLOAT32, new int[]{1, DIM_IMG_SIZE_X, DIM_IMG_SIZE_Y, 3})
                    .setOutputFormat(0, FirebaseModelDataType.FLOAT32, new int[]{1, 7})
                    .build();

            FirebaseCustomLocalModel localModel = new FirebaseCustomLocalModel.Builder().setAssetFilePath("mnist_model_quant.tflite").build();

            FirebaseModelInterpreterOptions modelOptions = new FirebaseModelInterpreterOptions.Builder(localModel).build();

            mInterpreter = FirebaseModelInterpreter.getInstance(modelOptions);

            // custom model

            float[][][][] imgData = convertByteArrayToByteBuffer(mImageData, mWidth, mHeight);

            FirebaseModelInputs inputs = new FirebaseModelInputs.Builder().add(imgData).build();

            mInterpreter
                    .run(inputs, mDataOptions)
                    .addOnSuccessListener(new OnSuccessListener<FirebaseModelOutputs>() {
                        @Override
                        public void onSuccess(FirebaseModelOutputs firebaseModelOutputs) {

                            float[][] labelProbArray = firebaseModelOutputs.<float[][]>getOutput(0);

                            for (int i = 0; i < labelProbArray[0].length; i++) {
                                System.out.println(labelProbArray[0][i]);
                            }

                            WritableArray result = Arguments.createArray();
                            result.pushString(String.valueOf(labelProbArray[0][0]));

                            System.out.println(result);

                            mDelegate.onCustomModel(result);
                            mDelegate.onCustomModelTaskCompleted();
                        }
                    })
                    .addOnFailureListener(
                            new OnFailureListener() {
                                @Override
                                public void onFailure(Exception e) {
                                    Log.e(TAG, "Custom model task failed" + e);
                                    mDelegate.onCustomModelTaskCompleted();
                                }
                            });

        } catch (FirebaseMLException | FileNotFoundException e) {
            //Toast.makeText(getReactApplicationContext(), "model load failed", 4).show();
            e.printStackTrace();
        }
        return null;
    }

    private synchronized float[][][][] convertByteArrayToByteBuffer(byte[] mImgData, int mWidth, int mHeight) throws FileNotFoundException {

        ByteArrayOutputStream out = new ByteArrayOutputStream();
        YuvImage yuvImage = new YuvImage(mImgData, ImageFormat.NV21, mWidth, mHeight, null);
        yuvImage.compressToJpeg(new Rect(0, 0, mWidth, mHeight), 100, out);
        byte[] imageBytes = out.toByteArray();
        Bitmap bitmap = BitmapFactory.decodeByteArray(imageBytes, 0, imageBytes.length);
        Bitmap scaledBitmap2 = Bitmap.createScaledBitmap(bitmap, DIM_IMG_SIZE_X, DIM_IMG_SIZE_Y, true);

        float[][][][] input = new float[1][DIM_IMG_SIZE_X][DIM_IMG_SIZE_Y][3];

        for (int x = 0; x < DIM_IMG_SIZE_X; x++) {
            for (int y = 0; y < DIM_IMG_SIZE_Y; y++) {
                int pixel = scaledBitmap2.getPixel(x, y);
                input[0][x][y][0] = ( Color.red(pixel) / 255.0f );
                input[0][x][y][1] = ( Color.green(pixel) / 255.0f );
                input[0][x][y][2] = ( Color.blue(pixel) / 255.0f );
            }
        }
        return input;
    }

}
